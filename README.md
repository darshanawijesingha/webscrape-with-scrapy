# webscrape-with-scrapy


# ğŸ›’ Keells Supermarket Product Scraper (Scrapy + Selenium)

This Scrapy project scrapes product data from [Keells Supermarket](https://www.keellssuper.com/) using **Selenium** for JavaScript rendering and **BeautifulSoup** for parsing.

---

## âœ… Features

- Scrapes from all main categories:
  - Snacks
  - Fresh Fruits
  - Grocery
  - Bakery
  - Chilled Products
  - Household Essentials
  - Electronic Devices
- Uses **Selenium scrolling** to load all products
- Extracts:
  - Category
  - Product Name
  - Final Price
  - Original Price (if available)
  - Discount (if available)
  - Image URL
- Exports scraped data to CSV file (via Scrapy CLI)

---

## ğŸ“ Project Structure

## ğŸ“‚ Project Structure

```text
keells_scraper/
â”œâ”€â”€ scrapy.cfg                       # Scrapy project configuration file
â”œâ”€â”€ keells_scraper/                 # Main project module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py                    # Define item structures
â”‚   â”œâ”€â”€ middlewares.py              # Custom middlewares (optional)
â”‚   â”œâ”€â”€ pipelines.py                # Item pipelines (optional)
â”‚   â”œâ”€â”€ settings.py                 # Project settings (configure feed/export here)
â”‚   â””â”€â”€ spiders/
â”‚       â””â”€â”€ all_keells_categories.py   # The spider that scrapes all categories
â”œâ”€â”€ screenshots/                    # Screenshots folder used in README
â”‚   â”œâ”€â”€ keells_home.png
â”‚   â”œâ”€â”€ keells_category.png
â”‚   â””â”€â”€ keells_snacks_view.png
â””â”€â”€ keells_all.csv                  # Final output CSV after spider run
```


## ğŸ›  Requirements

- Python 3.7+
- Google Chrome
- ChromeDriver (matching your Chrome version)

Install dependencies:

```bash
pip install scrapy selenium beautifulsoup4
```

#Run and Save Output
bash

scrapy crawl quotes_spider -o keells_all.csv



